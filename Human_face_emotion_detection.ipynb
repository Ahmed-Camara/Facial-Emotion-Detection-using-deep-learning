{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-Camara/Facial-Emotion-Detection-using-deep-learning/blob/main/Human_face_emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGeWRCv3FwRu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VFDIwEI4dLM9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization,ZeroPadding2D, Activation\n",
        "from tensorflow.keras.utils import plot_model \n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K7cA3YzWdILN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1mVxFygFzPZ",
        "outputId": "9c210503-32c0-42d7-8f55-10c4a9e705ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1AzS9JfF1iT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "#files = '/content/drive/MyDrive/DataSets/archive.zip'\n",
        "dataset_path = '/content/drive/MyDrive/ML_DL_practice/Human Face Emotion Detection/data/archive.zip'\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4DzOid_F5yM"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/dataset/train'\n",
        "test_path = '/content/dataset/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Weycg-VgF1lP"
      },
      "outputs": [],
      "source": [
        "os.listdir(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql2njt20GEb8"
      },
      "outputs": [],
      "source": [
        "def get_counts(path):\n",
        "  emotions = os.listdir(path)\n",
        "\n",
        "  cls_counts = {}\n",
        "  for emotion in emotions:\n",
        "    count = len(os.listdir(os.path.join(path, emotion)))\n",
        "    \n",
        "    cls_counts[emotion] = count\n",
        "\n",
        "  return cls_counts\n",
        "train_counts = get_counts(train_path)\n",
        "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize = (14, 8))\n",
        "\n",
        "explode = [0.05] * 7\n",
        "\n",
        "\n",
        "ax0.set_title('Train classes Pie chart')\n",
        "ax0.pie(train_counts.values(), labels=train_counts.keys(),\n",
        "       explode=explode, autopct='%1.1f%%', shadow=True)\n",
        "ax1.set_title('Train classes Bar chart')\n",
        "ax1.bar(train_counts.keys(), train_counts.values(), width=0.8)\n",
        "\n",
        "\n",
        "#fig.savefig('/content/pie_fer2013.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww81Rs-L_8ax"
      },
      "source": [
        "#### Hyperparameters && parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD47Dy3w__Mc"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (224, 224)\n",
        "epochs = 50\n",
        "base_learning_rate = 0.001\n",
        "fine_learning_rate = 1e-4\n",
        "dropout_factor = 0.5\n",
        "\n",
        "loss_function=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate)\n",
        "fine_optimizer = tf.keras.optimizers.RMSprop(learning_rate=fine_learning_rate)\n",
        "metrics=['accuracy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37G0MdMzCRiP"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDxRrvrdPLtJ"
      },
      "outputs": [],
      "source": [
        "train_dataset = image_dataset_from_directory(train_path,shuffle=True, batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMAGE_SIZE,validation_split=0.2,subset='training', seed = 42)\n",
        "validation_dataset = image_dataset_from_directory(train_path,shuffle=True, \n",
        "                                                  batch_size=BATCH_SIZE,image_size=IMAGE_SIZE,validation_split=0.2\n",
        "                                                  ,subset='validation', seed = 42)\n",
        "\n",
        "test_dataset = image_dataset_from_directory(test_path,shuffle=True, \n",
        "                                                  batch_size=BATCH_SIZE,image_size=IMAGE_SIZE\n",
        "                                                  , seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2yuiUVwGKay"
      },
      "outputs": [],
      "source": [
        "class_names = train_dataset.class_names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acIifJD5QXa7"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(15):\n",
        "        ax = plt.subplot(4,4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP0gSTricrM6"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-5lbjAnAWpc"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG1GIJkcQqN2"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
        "\n",
        "def data_augmenter():\n",
        "  data_augmentation = tf.keras.Sequential()\n",
        "  data_augmentation.add(RandomFlip('horizontal'))\n",
        "  data_augmentation.add(RandomRotation(0.2))\n",
        "  return data_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMScbDy0Q7OT"
      },
      "outputs": [],
      "source": [
        "data_augmentation = data_augmenter()\n",
        "for image, _ in train_dataset.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = image[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "        plt.imshow(augmented_image[0] / 255)\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLWou12qDhoW"
      },
      "source": [
        "In this project, we are using only transfer learning to build our models. First, we will train our model on top of the architecture then we will use fine-tuning model to increase our accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShPwWkayRNmq"
      },
      "outputs": [],
      "source": [
        "def draw_diagram(hist):\n",
        "  fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize = (16, 8))\n",
        "\n",
        "\n",
        "  ax0.plot(hist.history['accuracy'])\n",
        "  ax0.plot(hist.history['val_accuracy'])\n",
        "  ax0.set_title('Model Accuracy')\n",
        "  ax0.set_xlabel('Epochs')\n",
        "  ax0.set_ylabel('Accuracy')\n",
        "  ax0.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "\n",
        "\n",
        "  ax1.plot(hist.history['loss'])\n",
        "  ax1.plot(hist.history['val_loss'])\n",
        "  ax1.set_title('Model Loss')\n",
        "  ax1.set_xlabel('Epochs')\n",
        "  ax1.set_ylabel('Loss')\n",
        "  ax1.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "  fig.savefig('/content/fer_resutls.png')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkWc3QLiZOaM"
      },
      "outputs": [],
      "source": [
        "IMAGE_SHAPE = IMAGE_SIZE + (3,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceTUhRToAfnd"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model function"
      ],
      "metadata": {
        "id": "8bQqpW3x5YbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(image_shape=IMAGE_SHAPE,data_augmentation=data_augmenter(),mod='dense'):\n",
        "\n",
        "  input_shape = image_shape + (3,)\n",
        "  base_model = None\n",
        "  preprocess_input = None\n",
        "    \n",
        "  if mod == 'dense':\n",
        "    preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
        "    base_model = tf.keras.applications.DenseNet201(input_shape=input_shape,include_top=False,weights='imagenet')\n",
        "  \n",
        "  elif mod == 'efficientnet':\n",
        "    preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "    base_model = tf.keras.applications.EfficientNetB1(input_shape=input_shape,include_top=False,weights='imagenet')\n",
        "  \n",
        "  elif mod == 'resnet':\n",
        "    preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
        "    base_model = tf.keras.applications.ResNet101(input_shape=input_shape,include_top=False,weights='imagenet')\n",
        "  \n",
        "  base_model.trainable = False \n",
        "  inputs = tf.keras.Input(shape=input_shape)\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False)\n",
        "  x = tfl.GlobalAveragePooling2D()(x)\n",
        "  x = tfl.Dropout(dropout_factor)(x)\n",
        "  outputs = tfl.Dense(7)(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  return base_model,model"
      ],
      "metadata": {
        "id": "ZeRaadYU5XbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBx3Ku5DE_fH"
      },
      "source": [
        "##### callback Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq0K_rmMFC7h"
      },
      "outputs": [],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True)\n",
        "callbacks = [stop_early]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DenseNet"
      ],
      "metadata": {
        "id": "hcuIJT_FO14p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model, dense_model = build_model(IMAGE_SIZE,data_augmentation,'dense')"
      ],
      "metadata": {
        "id": "ACvjCuOT70hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model.summary()"
      ],
      "metadata": {
        "id": "SH03PbE1Tspt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dense_model.layers)"
      ],
      "metadata": {
        "id": "RsPbSH_fTyyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model.compile(loss=loss_function,\n",
        "              optimizer = optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "history = dense_model.fit(train_dataset,\n",
        "                         epochs=epochs,batch_size=BATCH_SIZE,\n",
        "                         validation_data=validation_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "bGI7yNSyTuG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_diagram(history)"
      ],
      "metadata": {
        "id": "m88b-Rph3tXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = dense_model.layers[5]\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 670\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "fine_epochs = history.epoch[-1] + 100\n",
        "\n",
        "\n",
        "dense_model.compile(loss=loss_function,\n",
        "              optimizer = fine_optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "\n",
        "history_fine = dense_model.fit(train_dataset,\n",
        "                         epochs=fine_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "rG28jNKCT9pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_diagram(history_fine)"
      ],
      "metadata": {
        "id": "cAFRzwpa3v0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_save_path = '/content/drive/MyDrive/ML_DL_practice/Human Face Emotion Detection/trained models'"
      ],
      "metadata": {
        "id": "paZcOjjcF0UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow import keras\n",
        "#dense_model.save(model_save_path)"
      ],
      "metadata": {
        "id": "D5U4O_p8Fv1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M_ar99oX8hs"
      },
      "source": [
        "### EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J14sp-FnYn4e"
      },
      "outputs": [],
      "source": [
        "base_model,eff_model = build_model(IMAGE_SIZE, data_augmentation,'efficientnet')\n",
        "eff_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eff_model.compile(loss=loss_function,\n",
        "              optimizer = optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "history = eff_model.fit(train_dataset,\n",
        "                         epochs=epochs,batch_size=BATCH_SIZE,\n",
        "                         validation_data=validation_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "DVuXqbZLmtYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_diagram(history)"
      ],
      "metadata": {
        "id": "IPpJ9Ire3Pyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDZJ3MKuYC2R"
      },
      "source": [
        "##### fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNJtWnygacjO"
      },
      "outputs": [],
      "source": [
        "base_model = eff_model.layers[2]\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 200\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "\n",
        "eff_model.compile(loss=loss_function,\n",
        "              optimizer = fine_optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "fine_epochs = history.epoch[-1] + 100\n",
        "\n",
        "history_fine = eff_model.fit(train_dataset,\n",
        "                         epochs=fine_epochs,batch_size=BATCH_SIZE,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset,callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_diagram(history_fine)"
      ],
      "metadata": {
        "id": "XBTmGnQc33NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfRf4FQazu3"
      },
      "source": [
        "### Resnet101"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model,res_model = build_model(IMAGE_SIZE, data_augmentation,'resnet')\n",
        "res_model.summary()"
      ],
      "metadata": {
        "id": "UJgcdBDhx1F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_model.compile(loss=loss_function,\n",
        "              optimizer = optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "history = res_model.fit(train_dataset,\n",
        "                         epochs=epochs,batch_size=BATCH_SIZE,\n",
        "                         validation_data=validation_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "kFpZHi8zauRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_diagram(history)"
      ],
      "metadata": {
        "id": "Ler43V2vIoSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = res_model.layers[4]\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 300\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "\n",
        "\n",
        "res_model.compile(loss=loss_function,\n",
        "              optimizer = fine_optimizer,\n",
        "              metrics=metrics)\n",
        "history_fine = res_model.fit(train_dataset,\n",
        "                         epochs=fine_epochs,\n",
        "                         validation_data=validation_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "16eM9jOByAQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_diagram(history_fine)"
      ],
      "metadata": {
        "id": "JthNbWKp0KFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Human_face_emotion_detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}